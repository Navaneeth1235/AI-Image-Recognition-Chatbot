import streamlit as st
import os
from PIL import Image
import google.generativeai as genai
import speech_recognition as sr
from gtts import gTTS
from io import BytesIO
import base64
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Function to get Gemini AI response
def get_gemini_response(input_text, speech_text, image):
    model = genai.GenerativeModel('gemini-1.5-flash')
    combined_input = f"{input_text}\n{speech_text}" if speech_text else input_text
    if combined_input.strip():
        response = model.generate_content([combined_input, image] if image else [combined_input])
        return response.text
    return "Please provide some input."

# Function to recognize speech input
def recognize_speech():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("Listening...")
        try:
            audio = recognizer.listen(source)
            text = recognizer.recognize_google(audio)
            return text
        except sr.UnknownValueError:
            return "Could not understand audio."
        except sr.RequestError:
            return "Error with the speech recognition service."

# Function to convert text to speech using gTTS
def text_to_speech(text):
    tts = gTTS(text=text, lang="en")
    audio_file = BytesIO()
    tts.write_to_fp(audio_file)
    audio_file.seek(0)
    return audio_file

# Streamlit App UI
st.set_page_config(page_title="Multi-Input AI App", layout="wide")

st.title("AI Image Recognition Chatbot")

# Initialize session state for speech text and audio file
if 'speech_text' not in st.session_state:
    st.session_state['speech_text'] = ""
if 'audio_file' not in st.session_state:
    st.session_state['audio_file'] = None

col1, col2 = st.columns(2)

with col1:
    st.subheader("ðŸ“œ Manual Text Input")
    input_text = st.text_area("Enter your prompt:", placeholder="Type your prompt here...")

    st.subheader("ðŸŽ¤ Speech-to-Text")
    if st.button("Start Speaking"):
        spoken_text = recognize_speech()
        if spoken_text and "Could not understand" not in spoken_text:
            st.write(f"Recognized: {spoken_text}")
            st.session_state['speech_text'] += " " + spoken_text  # Store recognized text
            st.rerun()  # Refresh UI to update the text area

    # Display recognized speech text
    st.text_area("Recognized Speech:", st.session_state['speech_text'], disabled=True)

with col2:
    st.subheader("ðŸ“¸ Upload an Image")
    uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png","avif"])
    image = Image.open(uploaded_file) if uploaded_file else None
    if image:
        st.image(image, caption="Uploaded Image", use_container_width=True)

# Combine both inputs
final_text = input_text.strip() + "\n" + st.session_state['speech_text'].strip()

if st.button("ðŸš€ Generate Response"):
    if not final_text.strip():
        st.warning("Please enter text or speak before generating a response.")
    else:
        with st.spinner("Generating response..."):
            response = get_gemini_response(input_text, st.session_state['speech_text'], image)
        st.success("Response generated!")
        st.write(response)

        # Convert response to speech
        st.session_state['audio_file'] = text_to_speech(response)

# Play TTS Audio
if st.session_state['audio_file']:
    st.audio(st.session_state['audio_file'], format="audio/mp3")

